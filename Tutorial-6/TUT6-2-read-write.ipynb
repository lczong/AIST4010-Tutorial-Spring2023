{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "_E4357geZF3Y"
      },
      "source": [
        "# TUT6-2-read-write\n",
        "\n",
        "## **1. Loading and Saving Tensors**\n",
        "\n",
        "For individual tensors, we can directly\n",
        "invoke the `load` and `save` functions\n",
        "to read and write them respectively.\n",
        "Both functions require that we supply a name,\n",
        "and `save` requires as input the variable to be saved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "EknoUFIpZF3a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "A4jzrgrSZF3b"
      },
      "source": [
        "We can now read the data from the stored file back into memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "csnDDI8XZF3b",
        "outputId": "4955214e-7a3e-46e4-d22f-1ad980955e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "hXISqkz_ZF3c"
      },
      "source": [
        "We can [**store a list of tensors and read them back into memory.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "NNxuppS0ZF3c",
        "outputId": "c0fceb1d-6514-45f6-fb80-a9347b2398be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "YYXAKSG-ZF3c"
      },
      "source": [
        "We can even [**write and read a dictionary that maps\n",
        "from strings to tensors.**]\n",
        "This is convenient when we want\n",
        "to read or write all the weights in a model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "NpyqrkSeZF3d",
        "outputId": "474d2e6c-e332-4510-8f82-31ab68c99157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 16,
        "id": "yt9WJLU-ZF3d"
      },
      "source": [
        "## **2. Loading and Saving Model Parameters**\n",
        "\n",
        "Saving individual weight vectors (or other tensors) is useful,\n",
        "but it gets very tedious if we want to save\n",
        "(and later load) an entire model.\n",
        "After all, we might have hundreds of\n",
        "parameter groups sprinkled throughout.\n",
        "For this reason the deep learning framework provides built-in functionalities\n",
        "to load and save entire networks.\n",
        "\n",
        "An important detail to note is that this\n",
        "saves model *parameters* and not the entire model.\n",
        "For example, if we have a 3-layer MLP,\n",
        "we need to specify the architecture separately.\n",
        "The reason for this is that the models themselves can contain arbitrary code,\n",
        "hence they cannot be serialized as naturally.\n",
        "Thus, in order to reinstate a model, we need\n",
        "to generate the architecture in code\n",
        "and then load the parameters from disk.\n",
        "(**Let us start with our familiar MLP.**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "qV4NZRa-ZF3d"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  \n",
        "        self.relu = nn.ReLU(inplace=True) \n",
        "        self.out = nn.Linear(256, 10)  \n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.hidden(X)\n",
        "        X = self.relu(X)\n",
        "        X = self.out(X)\n",
        "        return X\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 20,
        "id": "iwrkCZ5vZF3e"
      },
      "source": [
        "Next, we [**store the parameters of the model as a file**] with the name \"mlp.params\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "3Iq6yOboZF3e"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 24,
        "id": "4dPuHvNJZF3e"
      },
      "source": [
        "To recover the model, we instantiate a clone\n",
        "of the original MLP model.\n",
        "Instead of randomly initializing the model parameters,\n",
        "we [**read the parameters stored in the file directly**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "yCleeN57ZF3e",
        "outputId": "88c6ce88-7496-4d99-cef5-b0288413fb5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 28,
        "id": "Rkt3LI1CZF3e"
      },
      "source": [
        "Since both instances have the same model parameters,\n",
        "the computational result of the same input `X` should be the same.\n",
        "Let us verify this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "EeVRbDulZF3f",
        "outputId": "8ed1f245-7158-4827-dcd7-b0f08e6eb0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}